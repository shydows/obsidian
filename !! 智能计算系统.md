---
date: 2024-08-31T20:55:00
tags:
  - 笔记
---
https://www.bilibili.com/video/BV1d7411y7bh/?p=3&t=383.001353

==08.31==
教学相长 老师学的更多

![[Pasted image 20240901080020.png]]

==09.02==
![[Pasted image 20240901230607.png]]

**符号主义是火箭，但这个火箭没造好，或者造不好；
深度学习（行为主义）是梯子，还有很多缺陷，不能一步登天；**

连接主义：生物神经元和人工神经元就是老鼠和米老鼠之间的关系（关系不大）

目前是第二代智能计算系统，畅想第三代智能计算系统可能有无限的算力，将会对人工智能带来怎样的变化（模拟人脑大量的神经元、虚拟世界、通用人工智能沙盒）——**“三大主义”的统合**

==09.04==
https://www.bilibili.com/video/BV1d7411y7bh/?t=372.901367
![[Pasted image 20240906080953.png]]

==09.07==
 https://www.bilibili.com/video/BV1d7411y7bh/?p=2&t=182.517613
 ![[Pasted image 20240907084728.png]]
  ![[Pasted image 20240907085223.png]]
  ==？每次都按照梯度（最值）的方向下降，一定能保证解最优吗？==
  答案：不能！
  + 对于 ***凸函数*** ，梯度下降法能找到全局最优解；对于非凸函数（存在多个局部极小值、鞍点等），梯度下降法可能会陷入局部最优解或停留在鞍点，从而无法保证全局最优。
  + 梯度下降法对 ***初始值敏感*** ，通过 ***多次随机初始化*** 并选择最佳结果，可以提高找到全局最优解的概率。
  + 学习率（步长）的选择对算法的收敛性至关重要。如果学习率太大，可能会跳过最优解或导致不稳定；如果学习率太小，收敛速度会非常慢，甚至可能陷入局部最优。
  
==09.06==
https://www.bilibili.com/video/BV1d7411y7bh/?t=785.60344
![[Pasted image 20240906075845.png]] 
https://www.bilibili.com/video/BV1d7411y7bh/?p=2&t=84.537692
![[Pasted image 20240906122441.png]]

==09.10==
在神经网络真实的应用中很难找到一些解析的办法，基本都是用这种迭代（梯度下降）的方法

**TO-DO**: 顺着发展轨迹找经典论文
https://www.bilibili.com/video/BV1d7411y7bh?t=1057.7&p=2
![[Pasted image 20240910102527.png]]

==09.13==
Kurt hornik证明了理论上两层神经网络可以拟合任何函数，为什么还要深度神经网络呢？
答：区分理论和实践；假设一个函数用两层神经网络可能需要一千万个参数，但是如果用五层神经网络可能只需要一千个参数。

受算力限制，以前都只能做浅层神经网络，但是2006年，多亏**Hinton LeCun Bengio**三位的工作，开始有了深度学习，他们是深度学习的「三位开创者」

![[Pasted image 20240913175851.png]]
### 选择合适的激活函数
![[Pasted image 20240913213328.png]]![[Pasted image 20240913213435.png]]
![[Pasted image 20240913213819.png]]![[Pasted image 20240913213834.png]]![[Pasted image 20240913213852.png]]
### 损失函数
![[Pasted image 20240913221101.png]]![[Pasted image 20240913221141.png]]![[Pasted image 20240913221202.png]]
一个算法可以拥有多个不同的损失函数；
损失函数可以用来评价模型的好坏；
### 过拟合
![[Pasted image 20240913221348.png]]

==09.14==
过拟合 即是泛化能力差 ➡️【解决方法】正则化
![[Pasted image 20240914190826.png]]![[Pasted image 20240914190743.png]]
推理的时候都要考虑，只是训练的时候可能不考虑
样本数量越少越需要做交叉验证
![[Pasted image 20240914191815.png]]

==09.27==
CNN组成：
![[Pasted image 20240927172016.png]]![[Pasted image 20240927143256.png]]![[Pasted image 20240927145711.png]]![[Pasted image 20240927150006.png]]![[Pasted image 20240927150347.png]]![[Pasted image 20240927150810.png]]![[Pasted image 20240927151238.png]]![[Pasted image 20240927151452.png]]![[Pasted image 20240927171948.png]]

